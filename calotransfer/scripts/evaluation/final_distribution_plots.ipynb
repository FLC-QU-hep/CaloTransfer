{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51a52de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "import matplotlib.gridspec as gridspec\n",
    "from tqdm.notebook import tqdm  # Use notebook version for better display\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Custom imports - make sure these are in your path\n",
    "import utils.plot_evaluate as plot\n",
    "from utils.preprocessing_utils import read_hdf5_file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfa46a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "        # Use a serif font that's likely available\n",
    "        'font.family': 'serif',\n",
    "        'font.serif': ['DejaVu Serif', 'Liberation Serif', 'Computer Modern Roman', 'Bitstream Vera Serif'],\n",
    "        'font.size': 12,\n",
    "        'axes.labelsize': 14,\n",
    "        'axes.titlesize': 16,\n",
    "        'xtick.labelsize': 12,\n",
    "        'ytick.labelsize': 12,\n",
    "        'legend.fontsize': 12,\n",
    "        'figure.dpi': 300,\n",
    "        'savefig.dpi': 600,  # Higher DPI for publication quality\n",
    "        'savefig.format': 'pdf',  # PDF format is often preferred for publications\n",
    "        'savefig.bbox': 'tight',\n",
    "        'savefig.pad_inches': 0.1,\n",
    "        'axes.linewidth': 0.8,  # Slightly thinner axes lines\n",
    "        'lines.linewidth': 1.5,  # Slightly thicker plot lines\n",
    "        'lines.markersize': 4,  # Slightly smaller markers\n",
    "        # 'axes.grid': True,\n",
    "        'grid.alpha': 0.3\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcb6dfe",
   "metadata": {},
   "source": [
    "# final distribution plots for the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51efd93",
   "metadata": {},
   "source": [
    "## complete models ((diffusion + showerflow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c92563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# USER CONFIGURATION SECTION - FIXED VERSION\n",
    "# ========================================\n",
    "\n",
    "# Import paths from the cleaned paths file\n",
    "from utils.paths_trainings_cleaned import (\n",
    "    PW_ENTRIES, \n",
    "    BASE_PATH_SHOWERS, \n",
    "    GEANT4_PATH,\n",
    "    DISPLAY_NAME_MAP,\n",
    "    build_showers_paths\n",
    ")\n",
    "\n",
    "# Base paths\n",
    "BASE_PATH = BASE_PATH_SHOWERS\n",
    "RESULTS_DIR = './results/final_comparison'\n",
    "\n",
    "# Dataset sizes to include in final plots (must match keys in PW_ENTRIES)\n",
    "SELECTED_DATASET_SIZES = ['100_1-1000', '1k_1-1000', '10k_1-1000', '100k_1-1000']\n",
    "\n",
    "# Dataset size order and colors for plotting\n",
    "dataset_sizes_order = ['100', '1,000', '10,000', '100,000']\n",
    "dataset_colors = {\n",
    "    '100': '#3C493F',      \n",
    "    '1,000': '#6320EE',     \n",
    "    '10,000': '#5C9EAD',   \n",
    "    '100,000': '#EF767A',  \n",
    "}\n",
    "\n",
    "# Map dataset keys to the format expected by SHOWER_PATHS\n",
    "DATASET_TO_DISPLAY_MAP = {\n",
    "    '100_1-1000': 'D = 1 x 10^2',   # Note: must match SHOWER_PATHS keys exactly\n",
    "    '1k_1-1000': 'D = 1 x 10^3',\n",
    "    '10k_1-1000': 'D = 1 x 10^4',\n",
    "    '100k_1-1000': 'D = 1 x 10^5'\n",
    "}\n",
    "\n",
    "# Fix DISPLAY_NAME_SIMPLE to map to simple internal storage keys\n",
    "DISPLAY_NAME_SIMPLE = {\n",
    "    'D = 1 x 10^2': '100',\n",
    "    'D = 1 x 10^3': '1,000',\n",
    "    'D = 1 x 10^4': '10,000',\n",
    "    'D = 1 x 10^5': '100,000'\n",
    "}\n",
    "\n",
    "# Plot display labels - use LaTeX for better compatibility\n",
    "PLOT_DISPLAY_LABELS = {\n",
    "    '100': r'$D = 10^{2}$',        # 100 samples\n",
    "    '1,000': r'$D = 10^{3}$',      # 1,000 samples  \n",
    "    '10,000': r'$D = 10^{4}$',     # 10,000 samples\n",
    "    '100,000': r'$D = 10^{5}$'     # 100,000 samples\n",
    "}\n",
    "\n",
    "# Alternative: If you want to show the actual sample count\n",
    "PLOT_DISPLAY_LABELS_WITH_COUNT = {\n",
    "    '100': r'100 samples',\n",
    "    '1,000': r'1k samples',\n",
    "    '10,000': r'10k samples',\n",
    "    '100,000': r'100k samples'\n",
    "}\n",
    "\n",
    "# Alternative: More descriptive labels\n",
    "PLOT_DISPLAY_LABELS_DESCRIPTIVE = {\n",
    "    '100': r'$N = 10^{2}$ training samples',\n",
    "    '1,000': r'$N = 10^{3}$ training samples',\n",
    "    '10,000': r'$N = 10^{4}$ training samples',\n",
    "    '100,000': r'$N = 10^{5}$ training samples'\n",
    "}\n",
    "\n",
    "# ========================================\n",
    "# MANUALLY SELECT OPTIMAL TRAINING STEPS HERE\n",
    "# ========================================\n",
    "OPTIMAL_TRAINING_STEPS = {\n",
    "    'vanilla_full_v1_1_1000': {\n",
    "        '100_1-1000': 250_000,    # Updated based on your output\n",
    "        '1k_1-1000': 1_000_000,   # Updated based on your output\n",
    "        '10k_1-1000': 500_000,    # Updated based on your output\n",
    "        '100k_1-1000': 750_000,   # Updated based on your output\n",
    "    },\n",
    "    'finetune_full_v1_1_1000': {\n",
    "        '100_1-1000': 100_000,\n",
    "        '1k_1-1000': 50_000,\n",
    "        '10k_1-1000': 100_000,\n",
    "        '100k_1-1000': 250_000,\n",
    "    },\n",
    "    'finetune_top3_v1_1_1000': {\n",
    "        '100_1-1000': 1_000_000,\n",
    "        '1k_1-1000': 500_000,\n",
    "        '10k_1-1000': 750_000,\n",
    "        '100k_1-1000': 750_000,\n",
    "    },\n",
    "    'finetune_bitfit_v1_1_1000': {\n",
    "        '100_1-1000': 1_000_000,\n",
    "        '1k_1-1000': 750_000,\n",
    "        '10k_1-1000': 500_000,\n",
    "        '100k_1-1000': 500_000,\n",
    "    },\n",
    "    'lora_r8_v1_1_1000': {\n",
    "        '100_1-1000': 250_000,\n",
    "        '1k_1-1000': 10_000,\n",
    "        '10k_1-1000': 100_000,\n",
    "        '100k_1-1000': 200_000,\n",
    "    },\n",
    "    'lora_r106_v1_1_1000': {\n",
    "        '100_1-1000': 100_000,\n",
    "        '1k_1-1000': 100_000,\n",
    "        '10k_1-1000': 10_000,\n",
    "        '100k_1-1000': 50_000,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Build the proper shower paths using the function from paths_trainings_cleaned\n",
    "selected_strategies = [\n",
    "    'vanilla_full_v1_1_1000', \n",
    "    'finetune_full_v1_1_1000',\n",
    "    'finetune_top3_v1_1_1000',\n",
    "    'finetune_bitfit_v1_1_1000',\n",
    "    'lora_r8_v1_1_1000',\n",
    "    'lora_r106_v1_1_1000',\n",
    "\n",
    "]\n",
    "selected_pw_entries = {k: v for k, v in PW_ENTRIES.items() if k in selected_strategies}\n",
    "SHOWER_PATHS = build_showers_paths(BASE_PATH, selected_pw_entries, GEANT4_PATH, DISPLAY_NAME_MAP)\n",
    "\n",
    "# EMA configuration\n",
    "USE_EMA = True\n",
    "EMA_SUFFIX = '' if USE_EMA else '_no_ema'\n",
    "\n",
    "# GEANT4 reference path\n",
    "GEANT4_PATH_USED = GEANT4_PATH\n",
    "\n",
    "# Strategy display names\n",
    "strategy_names = {\n",
    "    'vanilla_full_v1_1_1000': 'From scratch',\n",
    "    'finetune_full_v1_1_1000': 'Full fine-tuned',\n",
    "    'finetune_top3_v1_1_1000': 'Top-3 fine-tuned',\n",
    "    'finetune_bitfit_v1_1_1000': 'BitFit',\n",
    "    'lora_r8_v1_1_1000': 'LoRA R8',\n",
    "    'lora_r106_v1_1_1000': 'LoRA R106',\n",
    "\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded successfully\")\n",
    "print(f\"Selected strategies: {selected_strategies}\")\n",
    "print(f\"Dataset sizes: {SELECTED_DATASET_SIZES}\")\n",
    "print(\"Available shower paths:\")\n",
    "for strategy, paths in SHOWER_PATHS.items():\n",
    "    print(f\"  {strategy}: {list(paths.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa47364",
   "metadata": {},
   "source": [
    "### 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b49d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerAnalysisNotebook:\n",
    "    \"\"\"Notebook-friendly shower analysis class.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_path: str, energy_scaling: float = 0.033):\n",
    "        self.base_path = base_path\n",
    "        self.energy_scaling = energy_scaling\n",
    "        \n",
    "    def load_shower_data(self, path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Load shower data from HDF5 file.\"\"\"\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"File not found: {path}\")\n",
    "            \n",
    "        dataset_names, incidents, showers = read_hdf5_file2(path)\n",
    "        return incidents.squeeze(), showers\n",
    "    \n",
    "    def load_geant4_reference(self, path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Load GEANT4 reference data.\"\"\"\n",
    "        dataset_names, incidents, showers = read_hdf5_file2(path)\n",
    "        showers /= self.energy_scaling  # Apply energy scaling to GEANT4\n",
    "        return incidents.squeeze(), showers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eee888",
   "metadata": {},
   "source": [
    "### 4. Load and process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0051db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analyzer\n",
    "analyzer = ShowerAnalysisNotebook(base_path=BASE_PATH)\n",
    "\n",
    "# Storage for all shower data\n",
    "all_shower_data = {}\n",
    "all_incident_data = {}\n",
    "\n",
    "# Load GEANT4 reference data first\n",
    "print(\"Loading GEANT4 reference data...\")\n",
    "geant4_incidents, geant4_showers = analyzer.load_geant4_reference(GEANT4_PATH)\n",
    "print(f\"GEANT4 data loaded: {geant4_showers.shape}\")\n",
    "\n",
    "# Progress tracking - only for the strategies we want\n",
    "total_configs = len(selected_strategies) * len(SELECTED_DATASET_SIZES)\n",
    "progress_bar = tqdm(total=total_configs, desc=\"Loading data\")\n",
    "\n",
    "# Process only the selected strategies\n",
    "for strategy_name in selected_strategies:\n",
    "    if strategy_name not in SHOWER_PATHS:\n",
    "        print(f\"WARNING: Strategy {strategy_name} not found in SHOWER_PATHS\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing strategy: {strategy_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Store shower and incident data for this strategy\n",
    "    all_shower_data[strategy_name] = {}\n",
    "    all_incident_data[strategy_name] = {}\n",
    "    \n",
    "    # Process each dataset size\n",
    "    for dataset_key in SELECTED_DATASET_SIZES:\n",
    "        optimal_step = OPTIMAL_TRAINING_STEPS[strategy_name].get(dataset_key)\n",
    "        \n",
    "        if optimal_step is None:\n",
    "            print(f\"  WARNING: No optimal step for {dataset_key} in {strategy_name}\")\n",
    "            progress_bar.update(1)\n",
    "            continue\n",
    "        \n",
    "        # Get the scientific notation display name used by SHOWER_PATHS\n",
    "        scientific_display_name = DATASET_TO_DISPLAY_MAP[dataset_key]\n",
    "        \n",
    "        # Get the path template from SHOWER_PATHS and substitute the training step\n",
    "        if scientific_display_name not in SHOWER_PATHS[strategy_name]:\n",
    "            print(f\"  WARNING: Display size {scientific_display_name} not found in SHOWER_PATHS for {strategy_name}\")\n",
    "            progress_bar.update(1)\n",
    "            continue\n",
    "            \n",
    "        shower_path_template = SHOWER_PATHS[strategy_name][scientific_display_name]\n",
    "        shower_path = shower_path_template.format(training_step=optimal_step)\n",
    "        \n",
    "        # Add the /showers.hdf5 suffix\n",
    "        shower_path = f\"{shower_path}/showers.hdf5\"\n",
    "        \n",
    "        print(f\"  Dataset {dataset_key}: step {optimal_step:,}\")\n",
    "        print(f\"    Path: {shower_path}\")\n",
    "        \n",
    "        try:\n",
    "            # Load generated showers\n",
    "            gen_incidents, gen_showers = analyzer.load_shower_data(shower_path)\n",
    "            \n",
    "            # Store with simple display name\n",
    "            simple_display_name = DISPLAY_NAME_SIMPLE[scientific_display_name]\n",
    "            all_shower_data[strategy_name][simple_display_name] = gen_showers\n",
    "            all_incident_data[strategy_name][simple_display_name] = gen_incidents\n",
    "            \n",
    "            print(f\"    Loaded shower data: {gen_showers.shape}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    ERROR: {str(e)}\")\n",
    "            \n",
    "        progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Data loading summary:\")\n",
    "print(f\"GEANT4: {geant4_showers.shape}\")\n",
    "for strategy, data in all_shower_data.items():\n",
    "    if isinstance(data, dict):\n",
    "        print(f\"{strategy}: {list(data.keys())}\")\n",
    "    else:\n",
    "        print(f\"{strategy}: {type(data)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE DISTRIBUTION PLOTS FOR EACH STRATEGY WITH ALL DATASET SIZES TOGETHER\n",
    "# ============================================================================\n",
    "\n",
    "import gc  # For garbage collection\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive backend to save memory\n",
    "\n",
    "# Dataset size order for plotting (consistent order)\n",
    "dataset_sizes_order = ['100,000', '10,000', '1,000', '100']\n",
    "\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"GENERATING DISTRIBUTION PLOTS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Create output directories for both strategies\n",
    "for strategy_name in selected_strategies:\n",
    "    strategy_display_name = strategy_names[strategy_name]\n",
    "    save_dir = f'{RESULTS_DIR}/{strategy_display_name.lower()}'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    print(f\"Created directory: {save_dir}\")\n",
    "\n",
    "# Process each strategy separately to manage memory\n",
    "for strategy_idx, strategy_name in enumerate(selected_strategies):\n",
    "    if strategy_name not in all_shower_data:\n",
    "        print(f\"No data for strategy {strategy_name}\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\nGenerating plots for {strategy_names[strategy_name]} strategy...\")\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    showers_list = [geant4_showers]  # Start with GEANT4\n",
    "    incidents_list = [geant4_incidents]\n",
    "    labels = ['Geant4']\n",
    "    colors = ['gray']  # GEANT4 in gray\n",
    "    \n",
    "    # Add each dataset size\n",
    "    for dataset_size in dataset_sizes_order:\n",
    "        if dataset_size in all_shower_data[strategy_name]:\n",
    "            showers_list.append(all_shower_data[strategy_name][dataset_size])\n",
    "            incidents_list.append(all_incident_data[strategy_name][dataset_size])\n",
    "            \n",
    "            # Use the display label for the plot\n",
    "            labels.append(PLOT_DISPLAY_LABELS[dataset_size])\n",
    "            colors.append(dataset_colors[dataset_size])\n",
    "    \n",
    "    if len(showers_list) <= 1:\n",
    "        print(f\"Not enough data for {strategy_name}\")\n",
    "        continue\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    showers_numpy = np.array(showers_list)\n",
    "    incidents_numpy = np.array(incidents_list)\n",
    "    \n",
    "    # Create simulation labels dict\n",
    "    simulation_labels = {label: None for label in labels}\n",
    "    \n",
    "    print(f\"Plotting {len(showers_list)} datasets: {labels}\")\n",
    "    \n",
    "    # Create each type of plot\n",
    "    plot_configurations = [\n",
    "        (plot.plot_calibration_histograms, True, 'calibration'),\n",
    "        (plot.plot_energy_sum, False, 'energy_sum'),\n",
    "        (plot.plot_occupancy, False, 'occupancy'),\n",
    "        (plot.plot_energy_layer, False, 'energy_layer'),\n",
    "        (plot.plot_radial_energy, False, 'radial_energy'),\n",
    "        (plot.plot_visible_energy, False, 'visible_energy'),\n",
    "    ]\n",
    "    \n",
    "    # Set save directory for this strategy\n",
    "    save_dir = f'{RESULTS_DIR}/{strategy_names[strategy_name].lower()}'\n",
    "    \n",
    "    for plot_idx, (plot_func, needs_incidents, plot_name) in enumerate(plot_configurations):\n",
    "        try:\n",
    "            print(f\"  Creating {plot_name} plot...\")\n",
    "            \n",
    "            args = [showers_numpy]\n",
    "            if needs_incidents:\n",
    "                args.append(incidents_numpy)\n",
    "            \n",
    "            # Call plot function\n",
    "            kl_divergences, wasserstein_dist = plot_func(\n",
    "                *args,\n",
    "                simulation_labels=simulation_labels,\n",
    "                colors=colors,\n",
    "                kl_divergences={},\n",
    "                wasserstein={},\n",
    "                training_strategy=strategy_names[strategy_name],\n",
    "                save_plot=True,\n",
    "                save_dir=save_dir\n",
    "            )\n",
    "            \n",
    "            # Clear matplotlib cache after each plot\n",
    "            plt.close('all')\n",
    "            \n",
    "            # Force garbage collection every 2 plots to free memory\n",
    "            if plot_idx % 2 == 1:\n",
    "                gc.collect()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    ERROR creating {plot_name}: {str(e)}\")\n",
    "            # Close any remaining plots and clear memory\n",
    "            plt.close('all')\n",
    "            gc.collect()\n",
    "    \n",
    "    # After completing all plots for this strategy, clear memory\n",
    "    print(f\"  Completed all plots for {strategy_names[strategy_name]}\")\n",
    "    \n",
    "    # Clear the strategy data from memory after plotting (except GEANT4)\n",
    "    if strategy_idx == 0:  # Keep data for first strategy in case needed\n",
    "        pass\n",
    "    else:  # Clear data for subsequent strategies\n",
    "        if strategy_name in all_shower_data:\n",
    "            del all_shower_data[strategy_name]\n",
    "        if strategy_name in all_incident_data:\n",
    "            del all_incident_data[strategy_name]\n",
    "    \n",
    "    # Clear numpy arrays and force garbage collection\n",
    "    del showers_numpy, incidents_numpy\n",
    "    plt.close('all')\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"  Memory cleared for {strategy_names[strategy_name]} strategy\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ALL PLOTS GENERATED!\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Final memory cleanup\n",
    "plt.close('all')\n",
    "gc.collect()\n",
    "print(\"Final memory cleanup completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a7569",
   "metadata": {},
   "source": [
    "### composition of generated plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb65164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_strategies = [\n",
    "    'vanilla_full_v1_1_1000', \n",
    "    # 'finetune_full_v1_1_1000',\n",
    "    # 'finetune_top3_v1_1_1000',\n",
    "    # 'finetune_bitfit_v1_1_1000',\n",
    "    # 'lora_r8_v1_1_1000',\n",
    "    # 'lora_r106_v1_1_1000',\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d69ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def combine_plots_for_paper(strategy_name, source_dir, output_dir=None, output_format='png'):\n",
    "    \"\"\"\n",
    "    Combines individual plots into two composite figures for publication.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    strategy_name : str\n",
    "        Name of the training strategy (e.g., 'from scratch', 'lora r8', 'bitfit')\n",
    "    source_dir : str\n",
    "        Directory containing the individual plot files\n",
    "    output_dir : str, optional\n",
    "        Directory to save the composite figures (defaults to source_dir)\n",
    "    output_format : str, optional\n",
    "        Output format ('png' or 'pdf'), defaults to 'png'\n",
    "    \"\"\"\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = source_dir\n",
    "    \n",
    "    # Determine output format based on strategy\n",
    "    if strategy_name.lower() in ['from scratch', 'full fine-tuned']:\n",
    "        format_ext = 'png'\n",
    "    else:\n",
    "        format_ext = 'pdf'\n",
    "    \n",
    "    # Override if explicitly specified\n",
    "    if output_format:\n",
    "        format_ext = output_format\n",
    "    \n",
    "    # Define the plot files for each composite figure\n",
    "    # Figure 1: Energy-related plots\n",
    "    figure1_plots = [\n",
    "        'Voxel_Energy_Spectrum_with_ratio.png',\n",
    "        'Sampling_Fraction_with_ratio.png', \n",
    "        'Visible_Energy_with_ratio.png'\n",
    "    ]\n",
    "    \n",
    "    # Figure 2: Spatial distribution plots\n",
    "    figure2_plots = [\n",
    "        'Occupancy_with_ratio.png',\n",
    "        'Longitudinal_Profile_with_ratio.png',\n",
    "        'Radial_Profile_with_ratio.png'\n",
    "    ]\n",
    "    \n",
    "    # Create composite figures\n",
    "    create_composite_figure(figure1_plots, source_dir, output_dir, \n",
    "                           f'{strategy_name.lower().replace(\" \", \"_\")}_energy_plots.{format_ext}', \n",
    "                           strategy_name, format_ext)\n",
    "    \n",
    "    create_composite_figure(figure2_plots, source_dir, output_dir,\n",
    "                           f'{strategy_name.lower().replace(\" \", \"_\")}_spatial_plots.{format_ext}',\n",
    "                           strategy_name, format_ext)\n",
    "    \n",
    "    print(f\"Composite figures created for {strategy_name} strategy:\")\n",
    "    print(f\"  - {output_dir}/{strategy_name.lower().replace(' ', '_')}_energy_plots.{format_ext}\")\n",
    "    print(f\"  - {output_dir}/{strategy_name.lower().replace(' ', '_')}_spatial_plots.{format_ext}\")\n",
    "\n",
    "def combine_all_strategies(base_dir, strategies, output_dir=None):\n",
    "    \"\"\"\n",
    "    Combines plots for all strategies with flexible strategy handling.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_dir : str\n",
    "        Base directory containing strategy subdirectories\n",
    "    strategies : list or dict\n",
    "        List of strategy names or dict mapping strategy_key -> display_name\n",
    "    output_dir : str, optional\n",
    "        Output directory for composite figures\n",
    "    \"\"\"\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = os.path.join(base_dir, 'composite_figures')\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Handle both list and dict inputs\n",
    "    if isinstance(strategies, dict):\n",
    "        strategy_items = strategies.items()\n",
    "    else:\n",
    "        strategy_items = [(s, s) for s in strategies]\n",
    "    \n",
    "    for strategy_key, display_name in strategy_items:\n",
    "        # Convert display name to directory name (lowercase, replace spaces with underscores)\n",
    "        dir_name = display_name.lower().replace(' ', '_').replace('-', '_')\n",
    "        strategy_dir = os.path.join(base_dir, dir_name)\n",
    "        \n",
    "        if os.path.exists(strategy_dir):\n",
    "            print(f\"\\nProcessing {display_name} strategy...\")\n",
    "            combine_plots_for_paper(display_name, strategy_dir, output_dir)\n",
    "        else:\n",
    "            print(f\"Warning: Directory {strategy_dir} not found!\")\n",
    "            # Try alternative directory naming\n",
    "            alt_dir_name = display_name.lower()\n",
    "            alt_strategy_dir = os.path.join(base_dir, alt_dir_name)\n",
    "            if os.path.exists(alt_strategy_dir):\n",
    "                print(f\"  Found alternative directory: {alt_strategy_dir}\")\n",
    "                combine_plots_for_paper(display_name, alt_strategy_dir, output_dir)\n",
    "            else:\n",
    "                print(f\"  Alternative directory {alt_strategy_dir} also not found!\")\n",
    "    \n",
    "    print(f\"\\nAll composite figures saved to: {output_dir}\")\n",
    "\n",
    "def create_comparison_figure(strategy_dirs, output_dir, plot_type='energy', strategy_names=None):\n",
    "    \"\"\"\n",
    "    Creates a comparison figure showing multiple strategies side by side.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    strategy_dirs : dict\n",
    "        Dictionary mapping strategy_name -> directory_path\n",
    "    output_dir : str\n",
    "        Output directory for comparison figure\n",
    "    plot_type : str\n",
    "        Either 'energy' or 'spatial' to determine which plots to compare\n",
    "    strategy_names : dict, optional\n",
    "        Mapping of directory keys to display names\n",
    "    \"\"\"\n",
    "    \n",
    "    if plot_type == 'energy':\n",
    "        plot_files = [\n",
    "            'Voxel_Energy_Spectrum_with_ratio.png',\n",
    "            'Sampling_Fraction_with_ratio.png',\n",
    "            'Visible_Energy_with_ratio.png'\n",
    "        ]\n",
    "        output_name = 'comparison_energy_plots.pdf'\n",
    "    else:  # spatial\n",
    "        plot_files = [\n",
    "            'Occupancy_with_ratio.png',\n",
    "            'Longitudinal_Profile_with_ratio.png',\n",
    "            'Radial_Profile_with_ratio.png'\n",
    "        ]\n",
    "        output_name = 'comparison_spatial_plots.pdf'\n",
    "    \n",
    "    num_strategies = len(strategy_dirs)\n",
    "    num_plots = len(plot_files)\n",
    "    \n",
    "    # Create grid (num_strategies rows, num_plots columns)\n",
    "    fig = plt.figure(figsize=(8*num_plots, 6*num_strategies))\n",
    "    \n",
    "    for row, (strategy_key, source_dir) in enumerate(strategy_dirs.items()):\n",
    "        # Get display name\n",
    "        if strategy_names and strategy_key in strategy_names:\n",
    "            display_name = strategy_names[strategy_key]\n",
    "        else:\n",
    "            display_name = strategy_key.replace('_', ' ').title()\n",
    "            \n",
    "        for col, plot_file in enumerate(plot_files):\n",
    "            filepath = os.path.join(source_dir, plot_file)\n",
    "            if os.path.exists(filepath):\n",
    "                img = Image.open(filepath)\n",
    "                ax = plt.subplot(num_strategies, num_plots, row*num_plots + col + 1)\n",
    "                ax.imshow(img)\n",
    "                ax.axis('off')\n",
    "                \n",
    "                # Add strategy label for leftmost plots\n",
    "                if col == 0:\n",
    "                    ax.set_ylabel(display_name, fontsize=16, fontweight='bold')\n",
    "                    ax.yaxis.set_label_coords(-0.05, 0.5)\n",
    "            else:\n",
    "                print(f\"Warning: {filepath} not found!\")\n",
    "    \n",
    "    plt.subplots_adjust(left=0.05, right=0.99, top=0.98, bottom=0.02, \n",
    "                       wspace=0.02, hspace=0.02)\n",
    "    \n",
    "    # Save\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, output_name)\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Comparison figure saved: {output_path}\")\n",
    "\n",
    "def create_composite_figure(plot_files, source_dir, output_dir, output_filename, strategy_name, output_format='png'):\n",
    "    \"\"\"\n",
    "    Creates a composite figure from individual plot files.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    plot_files : list\n",
    "        List of plot filenames to combine\n",
    "    source_dir : str\n",
    "        Directory containing the plot files\n",
    "    output_dir : str\n",
    "        Directory to save the composite figure\n",
    "    output_filename : str\n",
    "        Name of the output file\n",
    "    strategy_name : str\n",
    "        Strategy name for error handling\n",
    "    output_format : str\n",
    "        Output format ('png' or 'pdf')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load images\n",
    "    images = []\n",
    "    for plot_file in plot_files:\n",
    "        filepath = os.path.join(source_dir, plot_file)\n",
    "        if os.path.exists(filepath):\n",
    "            img = Image.open(filepath)\n",
    "            images.append(np.array(img))\n",
    "        else:\n",
    "            print(f\"Warning: {filepath} not found!\")\n",
    "            return\n",
    "    \n",
    "    # Get dimensions\n",
    "    heights = [img.shape[0] for img in images]\n",
    "    widths = [img.shape[1] for img in images]\n",
    "    \n",
    "    # Use the maximum height and sum of widths\n",
    "    max_height = max(heights)\n",
    "    total_width = sum(widths)\n",
    "    \n",
    "    # Create figure with proper sizing\n",
    "    # Adjust figure size to maintain aspect ratios\n",
    "    fig_width = 24  # inches\n",
    "    fig_height = fig_width * max_height / total_width * 0.95  # Slightly reduce height for better proportions\n",
    "    \n",
    "    fig = plt.figure(figsize=(fig_width, fig_height))\n",
    "    \n",
    "    # Create subplots\n",
    "    for i, img in enumerate(images):\n",
    "        ax = plt.subplot(1, 3, i+1)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Adjust spacing\n",
    "    plt.subplots_adjust(left=0.01, right=0.99, top=0.99, bottom=0.01, wspace=0.02)\n",
    "    \n",
    "    # Save the composite figure\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    \n",
    "    # Set DPI based on format\n",
    "    dpi = 300 if output_format.lower() == 'pdf' else 150\n",
    "    \n",
    "    plt.savefig(output_path, dpi=dpi, bbox_inches='tight', pad_inches=0.1, format=output_format)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  Saved: {output_path}\")\n",
    "\n",
    "def create_all_composite_figures(results_dir, strategy_names=None, selected_strategies=None):\n",
    "    \"\"\"\n",
    "    Main function to create all composite figures for all strategies found in directory.\n",
    "    All composite figures will be saved in PDF format to the composite_figures subdirectory.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results_dir : str\n",
    "        Base directory containing all strategy results\n",
    "    strategy_names : dict, optional\n",
    "        Dictionary mapping strategy keys to display names (not used in this version)\n",
    "    selected_strategies : list, optional\n",
    "        List of strategy keys to process (if None, processes all directories)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "    print(\"CREATING COMPOSITE FIGURES\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create composite_figures directory\n",
    "    composite_dir = os.path.join(results_dir, 'composite_figures')\n",
    "    os.makedirs(composite_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all directories in results_dir (use actual directory names)\n",
    "    all_dirs = [d for d in os.listdir(results_dir) \n",
    "                if os.path.isdir(os.path.join(results_dir, d)) \n",
    "                and d not in ['comparisons', 'composite_figures']]\n",
    "    \n",
    "    print(f\"Found directories: {all_dirs}\")\n",
    "    print(f\"Saving all composite figures to: {composite_dir}\")\n",
    "    \n",
    "    # Process each directory\n",
    "    for dir_name in all_dirs:\n",
    "        strategy_dir = os.path.join(results_dir, dir_name)\n",
    "        \n",
    "        # Use directory name as display name\n",
    "        display_name = dir_name\n",
    "        \n",
    "        print(f\"\\nCreating composite figures for: {display_name}\")\n",
    "        \n",
    "        # Check if composite figures already exist in composite_figures directory\n",
    "        safe_name = dir_name.replace(' ', '_').replace('-', '_')\n",
    "        pdf_energy = os.path.join(composite_dir, f\"{safe_name}_energy_plots.pdf\")\n",
    "        pdf_spatial = os.path.join(composite_dir, f\"{safe_name}_spatial_plots.pdf\") \n",
    "        \n",
    "        if os.path.exists(pdf_energy) and os.path.exists(pdf_spatial):\n",
    "            print(f\"  Composite figures already exist for {display_name}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Always use PDF format and save to composite_figures directory\n",
    "        try:\n",
    "            combine_plots_for_paper(display_name, strategy_dir, \n",
    "                                   output_dir=composite_dir, \n",
    "                                   output_format='pdf')\n",
    "        except Exception as e:\n",
    "            print(f\"  Error creating composite figures for {display_name}: {e}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"COMPOSITE FIGURES COMPLETED!\")\n",
    "    print(f\"All composite figures saved to: {composite_dir}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "# Example usage - simple and clean\n",
    "if __name__ == \"__main__\":\n",
    "    # Set your results directory\n",
    "    RESULTS_DIR = './results/final_comparison'\n",
    "    \n",
    "    # Create all composite figures (will be saved as PDFs in composite_figures directory)\n",
    "    create_all_composite_figures(RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18482ba3",
   "metadata": {},
   "source": [
    "# Showerflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb9fd82",
   "metadata": {
    "tags": [
     "showerflow"
    ]
   },
   "outputs": [],
   "source": [
    "# ShowerFlow Cluster Distribution Analysis\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "import json\n",
    "\n",
    "# Import project modules\n",
    "import utils.eval_utils_showerflow as eval_utils\n",
    "from utils.preprocessing_utils import read_hdf5_file2\n",
    "from configs import Configs\n",
    "\n",
    "# Configuration\n",
    "class AnalysisConfig:\n",
    "    def __init__(self):\n",
    "        self.pretrained = False # Set to True for finetuned models, False for vanilla\n",
    "        self.energy_range = '1-1000GeV'\n",
    "        self.selected_models = ['100k', '10k', '1k', '100']\n",
    "        self.display_layers = np.linspace(0, 41, 8).astype(int)\n",
    "        # 8 layers for 2x4 grid\n",
    "        self.output_dir = './results/for_paper/showerflow_analysis/appendix'\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Plot configuration\n",
    "PLOT_DISPLAY_LABELS = {\n",
    "    '100': r'$D = 10^{2}$', '1,000': r'$D = 10^{3}$', \n",
    "    '10,000': r'$D = 10^{4}$', '100,000': r'$D = 10^{5}$'\n",
    "}\n",
    "\n",
    "dataset_colors = {\n",
    "    '100': '#3C493F', '1,000': '#6320EE', \n",
    "    '10,000': '#5C9EAD', '100,000': '#EF767A'\n",
    "}\n",
    "\n",
    "DISPLAY_NAME_TO_SIMPLE = {\n",
    "    'D = 1 x 10^2': '100', 'D = 1 x 10^3': '1,000',\n",
    "    'D = 1 x 10^4': '10,000', 'D = 1 x 10^5': '100,000'\n",
    "}\n",
    "\n",
    "config = AnalysisConfig()\n",
    "os.makedirs(config.output_dir, exist_ok=True)\n",
    "\n",
    "def extract_sf_paths_from_entries(config: AnalysisConfig) -> Tuple[Dict[str, str], Dict[str, int]]:\n",
    "    \"\"\"Extract ShowerFlow paths from paths_training_cleaned.py\"\"\"\n",
    "    try:\n",
    "        from utils.paths_trainings_cleaned import SF_ENTRIES, BASE_PATH_SF, DATASET_DIR_MAP, DISPLAY_NAME_MAP\n",
    "    except ImportError:\n",
    "        import sys\n",
    "        sys.path.append('./utils')\n",
    "        from paths_trainings_cleaned import SF_ENTRIES, BASE_PATH_SF, DATASET_DIR_MAP, DISPLAY_NAME_MAP\n",
    "    \n",
    "    training_type = 'finetune' if config.pretrained else 'vanilla'\n",
    "    sf_key = f'{training_type}_1-1000' if '1-1000' in config.energy_range else f'{training_type}_10-90'\n",
    "    \n",
    "    if sf_key not in SF_ENTRIES:\n",
    "        raise ValueError(f\"Key {sf_key} not found in SF_ENTRIES\")\n",
    "    \n",
    "    entries = SF_ENTRIES[sf_key]\n",
    "    model_paths = {}\n",
    "    model_epochs = {}\n",
    "    \n",
    "    simplified_to_ds = {\n",
    "        '100k': '100k_1-1000', '10k': f'10k_{config.energy_range.replace(\"GeV\", \"\").lower()}',\n",
    "        '1k': f'1k_{config.energy_range.replace(\"GeV\", \"\").lower()}',\n",
    "        '100': f'100_{config.energy_range.replace(\"GeV\", \"\").lower()}'\n",
    "    }\n",
    "    \n",
    "    for ds_key, date_folder, best_epoch in entries:\n",
    "        for simplified_name in config.selected_models:\n",
    "            expected_key = simplified_to_ds.get(simplified_name)\n",
    "            if expected_key and ds_key == expected_key:\n",
    "                display_name = DISPLAY_NAME_MAP.get(ds_key, ds_key)\n",
    "                dir_name = DATASET_DIR_MAP.get(ds_key, ds_key)\n",
    "                path = f\"{BASE_PATH_SF}/Shower_flow_weights/{dir_name}/{training_type}/ShowerFlow_{date_folder}/ShowerFlow_{best_epoch}.pth\"\n",
    "                model_paths[display_name] = path\n",
    "                model_epochs[display_name] = int(best_epoch)\n",
    "    \n",
    "    return model_paths, model_epochs\n",
    "\n",
    "def load_original_data(energy_range: str = '1-1000GeV', dim: str = '10k'):\n",
    "    \"\"\"Load the original CaloChallenge data\"\"\"\n",
    "    from utils.paths_configs import sf_eval_paths as dataset_paths\n",
    "    eval_ds = '1-1000GeV' if '1-1000' in energy_range else '10-90GeV'\n",
    "    \n",
    "    if eval_ds not in dataset_paths or dim not in dataset_paths[eval_ds]:\n",
    "        raise ValueError(f\"Invalid dataset: {eval_ds}, {dim}\")\n",
    "    \n",
    "    paths = dataset_paths[eval_ds][dim]\n",
    "    keys, energy, events = read_hdf5_file2(paths['data_path'])\n",
    "    clusters_per_layer = np.load(paths['clusters_per_layer_path'])\n",
    "    return energy, clusters_per_layer\n",
    "\n",
    "def plot_cluster_distributions(original_clusters: pd.Series, samples_dict: Dict[str, np.ndarray], \n",
    "                              display_layers: list, norm: float = 1.0, save_path: Optional[str] = None):\n",
    "    \"\"\"Plot cluster distributions for selected layers in a 2x4 grid with adaptive binning\"\"\"\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(24, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    pretrained = config.pretrained\n",
    "    training_strategy = 'Fine-tuned' if pretrained else 'From scratch'\n",
    "    wasserstein_distances = {model: [] for model in samples_dict}\n",
    "    \n",
    "    for idx, layer in enumerate(display_layers):\n",
    "        ax = axes[idx]\n",
    "        original_layer_data = original_clusters.apply(lambda x: x[layer])\n",
    "        \n",
    "        # Calculate adaptive bins based on data range\n",
    "        max_val = original_layer_data.max()\n",
    "        # Add check for generated samples max too\n",
    "        for samples in samples_dict.values():\n",
    "            sample_max = np.round(samples[:, 2 + layer] * norm).max()\n",
    "            max_val = max(max_val, sample_max)\n",
    "        \n",
    "        # Adaptive binning: aim for ~8-12 units per bin, constrain between 20-80 bins\n",
    "        target_width = 18\n",
    "        n_bins = max(15, min(50, int(max_val / target_width)))\n",
    "        \n",
    "        h = ax.hist(original_layer_data, bins=n_bins, color='lightgrey', label='GEANT4', alpha=0.7)\n",
    "        \n",
    "        for model_name, samples in samples_dict.items():\n",
    "            layer_sample_data = samples[:, 2 + layer] * norm\n",
    "            layer_sample_data = np.round(layer_sample_data)\n",
    "            \n",
    "            simple_key = DISPLAY_NAME_TO_SIMPLE.get(model_name, model_name)\n",
    "            color = dataset_colors.get(simple_key, 'black')\n",
    "            plot_label = PLOT_DISPLAY_LABELS.get(simple_key, model_name)\n",
    "            \n",
    "            counts, bin_edges = np.histogram(layer_sample_data, bins=h[1])\n",
    "            \n",
    "            # Create extended arrays that start at x=0\n",
    "            # Prepend zero to ensure the line starts at (0, 0)\n",
    "            extended_edges = np.concatenate([[0], bin_edges])\n",
    "            extended_counts = np.concatenate([[0], counts, [0]])  # Add zero at end too for clean closure\n",
    "            \n",
    "            # Use stairs instead of step for cleaner control\n",
    "            ax.stairs(extended_counts[:-1], extended_edges, linewidth=3, color=color, label=plot_label)\n",
    "            \n",
    "            # Alternative: if you prefer to use step, you can do:\n",
    "            # bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "            # extended_centers = np.concatenate([[0], bin_centers])\n",
    "            # extended_counts = np.concatenate([[0], counts])\n",
    "            # ax.step(extended_centers, extended_counts, where='mid', linewidth=2, color=color, label=plot_label)\n",
    "\n",
    "            if idx == 0:\n",
    "                ax.set_title(f'{training_strategy}', loc='right', fontsize=30, pad=20, weight='bold')\n",
    "\n",
    "            from scipy.stats import wasserstein_distance\n",
    "            wd = wasserstein_distance(original_layer_data, layer_sample_data)\n",
    "            wasserstein_distances[model_name].append(wd)\n",
    "        \n",
    "        ax.set_xlabel(f'Points in Layer {layer + 1}', fontsize=24)\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_xlim(0, 670)\n",
    "        ax.set_ylim(1e1, 1e4)\n",
    "        ax.tick_params(axis='x', labelsize=24)\n",
    "        ax.tick_params(axis='y', labelsize=24)\n",
    "        \n",
    "        if idx == 0:\n",
    "            ax.legend(loc='upper right', fontsize=24, frameon=False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Saved figure to {save_path}\")\n",
    "    plt.show()\n",
    "    \n",
    "    return {model: np.mean(distances) for model, distances in wasserstein_distances.items()}\n",
    "\n",
    "\n",
    "# Extract paths and load data\n",
    "model_paths, model_epochs = extract_sf_paths_from_entries(config)\n",
    "energy, original_clusters_per_layer = load_original_data(energy_range=config.energy_range)\n",
    "\n",
    "print(f\"Using {'finetuned' if config.pretrained else 'vanilla'} models for {config.energy_range}\")\n",
    "print(f\"Loaded data: energy shape {energy.shape}, clusters shape {original_clusters_per_layer.shape}\")\n",
    "\n",
    "# Load models and generate samples\n",
    "_, distributions, model_name_to_index = eval_utils.load_models_and_distributions(\n",
    "    model_paths, config.device, num_blocks=2, num_inputs=92\n",
    ")\n",
    "\n",
    "cfg = Configs()\n",
    "samples_dict = eval_utils.generate_samples(\n",
    "    distributions, model_name_to_index, cfg, energy, config.device,\n",
    "    min_energy=energy.min(), max_energy=energy.max()\n",
    ")\n",
    "\n",
    "# Generate plots\n",
    "clusters_series = pd.Series(list(original_clusters_per_layer))\n",
    "training_type = 'Fine-tuned' if config.pretrained else 'Vanilla'\n",
    "save_path = os.path.join(config.output_dir, \n",
    "                        f\"cluster_distributions_{training_type.lower()}_{config.energy_range.replace('GeV', '')}.pdf\")\n",
    "\n",
    "mean_distances = plot_cluster_distributions(\n",
    "    original_clusters=clusters_series, samples_dict=samples_dict,\n",
    "    display_layers=config.display_layers, norm=cfg.sf_norm_points, save_path=save_path\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n{'='*60}\\nANALYSIS SUMMARY\\n{'='*60}\")\n",
    "print(f\"Training Type: {training_type}\")\n",
    "print(f\"Energy Range: {config.energy_range}\")\n",
    "print(f\"Models Analyzed: {list(samples_dict.keys())}\")\n",
    "print(\"Mean Wasserstein Distances:\")\n",
    "for model, distance in mean_distances.items():\n",
    "    display_label = PLOT_DISPLAY_LABELS.get(DISPLAY_NAME_TO_SIMPLE.get(model, model), model)\n",
    "    print(f\"  {display_label}: {distance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e71f923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calo-transfer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
